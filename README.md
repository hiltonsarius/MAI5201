# MAI5201: Natural Language Processing @UG

This course provides a broad introduction to the fundamental concepts, tasks, and techniques of natural language processing, and its recent advances based on machine learning algorithms (e.g., neural networks) and applications for interdisciplinary subjects. Students will explore applications such as information retrieval and extraction, intelligent web searching, speech recognition, and machine translation.

| | |
|---|---|
| Course Code | MAI5201 |
| Course Name | Natural Language Processing |
| Trimester | 2 |
| Teaching Modality | Online |
| Course Repository | GitHub Repository |
| Course Credits | 4 |
| Pre-requisites | MAI5101 - Fundamentals of Artificial Intelligence (must be completed and passed) |
| Timetabling | Live Lectures: Tuesday & Thursday 8:30 pm ‚Äì 10:00 pm (GYD) |
| Duration | Tuesday, 15-July-2025 - Thursday, 30-October-2025 |
| Course Leader | Dr. Christopher Clarke |
| Academic Year | 2024/2025 |

## Course Delivery

This course will be delivered as an online learning program, including:

‚Ä¢ Online discussions  
‚Ä¢ Written assignments  
‚Ä¢ Research paper presentations  
‚Ä¢ Individual projects and presentations  

Lectures will be conducted via Zoom, and course materials will be available via the GitHub Course Page.

üìå **Time Commitment**: Students should allocate approximately 8-12 hours per week aside from lectures for self-study, assignments, and project work.

üìñ **Course Textbook**: Daniel Jurafsky and James H. Martin. 2025. *Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition with Language Models*, 3rd edition.

## üóìÔ∏è Weekly Schedule

| Week | Topics | Readings | Assignments |
|------|--------|----------|-------------|
| 1 | **Introduction to Natural Language Processing**<br>- What is NLP?<br>- Historical development<br>- Core NLP tasks and applications<br>- Challenges in NLP<br>Slides: [Introduction](slides/week1/intro.md) \| [PDF](slides/week1/intro.pdf) | Chapter 1: Introduction | - [HW 0 Released](hw/hw0/README.md)<br>- Environment Setup |
| 2 | **Text Processing Fundamentals**<br>- Regular Expressions<br>- Tokenization<br>- Edit Distance<br>- Text Normalization<br>Slides: [Text Processing](slides/week1/text_processing.pdf) \| [Medical AI Overview](slides/week2/med24.pdf) | Chapter 2: Regular Expressions, Text Normalization, and Edit Distance | - [Project Guidelines Released](#course-project) |
| 3 | **N-gram Language Models**<br>- Statistical Language Models<br>- N-gram Models<br>- Smoothing Techniques<br>- Evaluation of Language Models<br>Slides: [Language Models](slides/week3/lm_jan25.pdf) | Chapter 3: N-gram Language Models | - [HW 0 Due](hw/hw0/README.md)<br>- HW 1 Released |
| 4 | **Text Classification & Sentiment Analysis**<br>- Naive Bayes Classification<br>- Feature Engineering<br>- Sentiment Analysis<br>- Evaluation Metrics<br>Slides: [Lecture 4] | Chapter 4: Naive Bayes Classification and Sentiment | - [Paper Summary 1: ELIZA Due](paper-summaries/assignment-1/README.md)<br>- Paper Presentation 1 |
| 5 | **Logistic Regression**<br>- Binary and Multiclass Classification<br>- Feature Engineering<br>- Regularization<br>- Cross-validation<br>Slides: [Lecture 5] | Chapter 5: Logistic Regression | - HW 1 Due<br>- HW 2 Released<br>- [Paper Summary 2: BPE Released](paper-summaries/assignment-2/README.md) |
| 6 | **Vector Semantics and Embeddings**<br>- Distributional Semantics<br>- TF-IDF and PMI<br>- Word2Vec and GloVe<br>- Semantic Similarity<br>Slides: [Lecture 6] | Chapter 6: Vector Semantics and Embeddings | - [Paper Summary 2: BPE Due](paper-summaries/assignment-2/README.md)<br>- Project Proposal Due |
| 7 | **Neural Networks for NLP**<br>- Feedforward Networks<br>- Backpropagation<br>- Neural Language Models<br>- Word Embeddings<br>Slides: [Lecture 7] | Chapter 7: Neural Networks and Neural Language Models | - HW 2 Due<br>- HW 3 Released |
| 8 | **RNNs and LSTMs**<br>- Recurrent Neural Networks<br>- Long Short-Term Memory<br>- Gated Recurrent Units<br>- Sequence-to-Sequence Models<br>Slides: [Lecture 8] | Chapter 9: RNNs and LSTMs | - Paper Presentation 2 |
| 9 | **Transformers**<br>- Attention Mechanisms<br>- Self-Attention<br>- Transformer Architecture<br>- BERT and GPT Introduction<br>Slides: [Lecture 9] | Chapter 10: Transformers and Pretrained Language Models | - HW 3 Due<br>- HW 4 Released |
| 10 | **Large Language Models**<br>- GPT Family Models<br>- Scaling Laws<br>- Emergent Abilities<br>- Training and Inference<br>Slides: [Lecture 10] | Chapter 12: Prompting, In-Context Learning, and Instruction Tuning | - Project Progress Report |
| 11 | **Masked Language Models**<br>- BERT and Variants<br>- Pre-training Objectives<br>- Fine-tuning Strategies<br>- Task-specific Applications<br>Slides: [Lecture 11] | Chapter 11: Transfer Learning with Pretrained Language Models | - HW 4 Due<br>- HW 5 Released |
| 12 | **Model Alignment & Advanced Techniques**<br>- Prompting Strategies<br>- In-Context Learning<br>- Instruction Tuning<br>- RLHF and Alignment<br>Slides: [Lecture 12] | Chapter 12: Prompting, In-Context Learning, and Instruction Tuning | - Paper Presentation 3 |
| 13 | **Advanced NLP Applications**<br>- Information Extraction<br>- Question Answering<br>- Machine Translation<br>- Dialogue Systems<br>Slides: [Lecture 13] | Selected Chapters and Recent Papers | - HW 5 Due |
| 14 | **Ethics in NLP & Current Research**<br>- Bias in Language Models<br>- Fairness and Transparency<br>- Current Research Frontiers<br>- Course Review<br>Slides: [Lecture 14] | Recent Papers on Ethics and Bias | |
| 15 | **Project Presentations** | No Readings | - Final Project Due<br>- Project Presentations |

üìå **DUE DATES**: All assignments are due before 11:59 PM (Guyana time) on the specified date unless otherwise stated.

üìå **Instructor Adjustments**: The instructor reserves the right to modify the course schedule as needed. Any changes will be communicated via email and course announcements.

## Assignments & Course Project

### Homework Assignments

There will be 5 homework assignments designed to cover core NLP concepts, including:

‚Ä¢ Text processing and regular expressions  
‚Ä¢ Language modeling and classification  
‚Ä¢ Neural networks and embeddings  
‚Ä¢ Transformer models and applications  
‚Ä¢ Advanced NLP techniques  

üìå **Late Policy**: Homeworks cannot be turned in late unless an extension is granted at least 24 hours before the submission deadline.

üìå **Homework Drop**: The lowest homework score will be dropped at the end of the semester.

### Research Paper Presentations

Each student must present one research paper on a core NLP topic. Presentations should be 15-20 minutes followed by 5-10 minutes of discussion.

üìå **Paper Selection**: Students must select papers from a provided list or get approval for alternative papers by Week 3.

üìå **Presentation Requirements**:
‚Ä¢ Clear explanation of the research problem
‚Ä¢ Methodology and key contributions
‚Ä¢ Critical analysis and limitations
‚Ä¢ Relevance to course topics

### Paper Summaries

An important aspect of doing cutting-edge AI engineering and problem solving is being able to read papers. Particularly now more than ever, developments in the science are required to envision solutions to engineering challenges in AI.

Each student is expected to read assigned research papers before their presentation and submit a paragraph summary addressing the following questions:

üìå **Summary Requirements**:
‚Ä¢ What is most interesting in the paper?
‚Ä¢ What could the paper have done better in either how it's written or the research itself?
‚Ä¢ What questions do you have from what you read in the paper?

üìå **Submission**: Submit one paragraph (150-250 words) for each assigned paper before the presentation date.

üìå **Purpose**: Develop critical reading skills and prepare for meaningful discussion during paper presentations.

üìå **Assignments**: See [Paper Summaries Directory](paper-summaries/README.md) for specific assignments and submission guidelines.

## Course Project

Students must choose between two project directions:

### 1Ô∏è‚É£ Applied NLP Project

‚Ä¢ Develop an NLP-based application to solve a real-world problem
‚Ä¢ Implement and evaluate NLP techniques learned in the course

üìå **Possible Applications**:
‚Ä¢ Sentiment analysis for social media monitoring
‚Ä¢ Text classification for document organization
‚Ä¢ Information extraction from domain-specific texts
‚Ä¢ Chatbot or dialogue system for specific use cases
‚Ä¢ Machine translation for low-resource languages

üìå **Deliverables**:
‚Ä¢ Week 6 ‚Äì Project Proposal (Problem definition, approach, and dataset)
‚Ä¢ Week 10 ‚Äì Progress Report (Implementation status and preliminary results)
‚Ä¢ Week 15 ‚Äì Final Submission (Working NLP application, 6-8 page technical report, code repository)
‚Ä¢ Week 15 ‚Äì Demo & Presentation (15-20 minutes)

### 2Ô∏è‚É£ Research-Oriented NLP Project

‚Ä¢ Implement and evaluate a model from a recent research paper
‚Ä¢ Propose and investigate novel research ideas in NLP

üìå **Possible Research Areas**:
‚Ä¢ Improving language model performance on specific tasks
‚Ä¢ Bias detection and mitigation in NLP systems
‚Ä¢ Few-shot learning for NLP applications
‚Ä¢ Multilingual NLP and cross-lingual transfer
‚Ä¢ Evaluation metrics for generative language models

üìå **Deliverables**:
‚Ä¢ Week 6 ‚Äì Research Proposal (Research question, motivation, and methodology)
‚Ä¢ Week 10 ‚Äì Progress Report (Implementation status, experiments, and preliminary findings)
‚Ä¢ Week 15 ‚Äì Final Report (6-8 page research paper following ACL format)
‚Ä¢ Week 15 ‚Äì Presentation (15-20 minutes)

## Project Requirements

1. **Real-world Relevance** ‚Äì Your project must address a practical NLP problem or advance NLP research.
2. **NLP-Driven, Not Just Software Engineering** ‚Äì This is not an app-building course; focus on NLP techniques.
3. **Clear Problem Statement** ‚Äì Define the NLP challenge you're solving.
4. **Appropriate Techniques** ‚Äì Use methods and concepts from the course.
5. **Proper Evaluation** ‚Äì Include appropriate metrics and baselines.
6. **Reproducibility & Documentation** ‚Äì Code must be well-documented and results reproducible.
7. **Ethical Considerations** ‚Äì Address potential biases, privacy concerns, and responsible AI principles.
8. **Literature Review** ‚Äì Demonstrate understanding of related work in your area.

## Assessment Structure

| Component | Weight |
|-----------|---------|
| Homework Assignments (5 total, lowest dropped) | 40% |
| Research Paper Presentation | 10% |
| Class Participation | 5% |
| Paper Summaries | 5% |
| Course Project | 40% |
| **Total** | **100%** |

## Grading System

| Grade | Percentage |
|-------|------------|
| A | 80% - 100% |
| B | 70% - 79% |
| C | 60% - 69% |
| F | < 60% |

## Submission & Academic Integrity

‚Ä¢ Submit assignments via GitHub/Moodle by 11:59 PM (GYD).
‚Ä¢ **Plagiarism Policy**: You may not directly copy code or text without proper attribution.
‚Ä¢ **Use of Generative AI**: Allowed as a collaborator for brainstorming and debugging, but must be acknowledged and cannot replace your core contribution.

üìå **Honor Code**: Misuse of generative AI tools or plagiarism will be treated as an academic violation.

## Required Software & Tools

‚Ä¢ **Python 3.8+** with packages: NLTK, spaCy, scikit-learn, pandas, numpy
‚Ä¢ **Deep Learning**: PyTorch or TensorFlow
‚Ä¢ **Transformers**: Hugging Face Transformers library
‚Ä¢ **Development Environment**: Jupyter Notebooks, Google Colab (recommended)
‚Ä¢ **Version Control**: Git and GitHub

## Course Resources

### Primary Textbook
‚Ä¢ Jurafsky, D. & Martin, J.H. (2025). *Speech and Language Processing*, 3rd Ed.

### Supplementary Resources
‚Ä¢ Selected research papers from ACL, EMNLP, NAACL, and other top-tier venues
‚Ä¢ Online tutorials and documentation for NLP libraries
‚Ä¢ Course GitHub repository with code examples and datasets

### Useful Websites
‚Ä¢ [Hugging Face](https://huggingface.co/) - Pre-trained models and datasets
‚Ä¢ [Papers with Code](https://paperswithcode.com/area/natural-language-processing) - Latest NLP research
‚Ä¢ [ACL Anthology](https://aclanthology.org/) - NLP research papers

## Communication

‚Ä¢ **Course Announcements**: Via email and GitHub
‚Ä¢ **Questions**: Use GitHub Issues or email Dr. Clarke
‚Ä¢ **Office Hours**: By appointment
‚Ä¢ **Class Discussions**: Encouraged during and after lectures

---

*This course is designed to provide students with both theoretical understanding and practical skills in natural language processing, preparing them for advanced research or industry applications in NLP and AI.*